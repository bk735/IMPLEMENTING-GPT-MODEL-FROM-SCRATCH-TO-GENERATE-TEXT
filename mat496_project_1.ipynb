{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bk735/IMPLEMENTING-GPT-MODEL-FROM-SCRATCH-TO-GENERATE-TEXT/blob/main/mat496_project_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NLQopQNQTUmc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3816590e-e00c-4bd0-9ef4-f7e5e05ff235"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2025.1.31)\n",
            "Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.6/1.2 MB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tiktoken\n",
            "Successfully installed tiktoken-0.9.0\n"
          ]
        }
      ],
      "source": [
        "!pip install tiktoken"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from importlib.metadata import version\n",
        "import tiktoken\n",
        "print(\"torch version:\", version(\"torch\"))\n",
        "print(\"tiktoken version:\", version(\"tiktoken\"))"
      ],
      "metadata": {
        "id": "35VfUjrIV2yg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "091518ec-542b-46ff-d9c3-18bcc1cb71ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch version: 2.6.0+cu124\n",
            "tiktoken version: 0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import urllib.request\n",
        "\n",
        "file_path_1 = \"text_data_1.txt\"\n",
        "url = \"https://www.gutenberg.org/cache/epub/1342/pg1342.txt\"\n",
        "\n",
        "if not os.path.exists(file_path_1):\n",
        "    with urllib.request.urlopen(url) as response:\n",
        "        text_data_1 = response.read().decode('utf-8')\n",
        "    with open(file_path_1, \"w\", encoding=\"utf-8\") as file:\n",
        "        file.write(text_data_1)\n",
        "else:\n",
        "    with open(file_path_1, \"r\", encoding=\"utf-8\") as file:\n",
        "        text_data_1 = file.read()\n"
      ],
      "metadata": {
        "id": "N96d_qDb1KQG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_path_2 = \"text_data_2.txt\"\n",
        "url = \"https://www.gutenberg.org/cache/epub/1400/pg1400.txt\"\n",
        "\n",
        "if not os.path.exists(file_path_2):\n",
        "    with urllib.request.urlopen(url) as response:\n",
        "        text_data_2 = response.read().decode('utf-8')\n",
        "    with open(file_path_2, \"w\", encoding=\"utf-8\") as file:\n",
        "        file.write(text_data_2)\n",
        "else:\n",
        "    with open(file_path_2, \"r\", encoding=\"utf-8\") as file:\n",
        "        text_data_2 = file.read()"
      ],
      "metadata": {
        "id": "P-Dt_H0E1Pog"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = text_data_1 + text_data_2\n",
        "assert(len(dataset) == len(text_data_1) + len(text_data_2))"
      ],
      "metadata": {
        "id": "67VIhQNa1t7U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"final_dataset.txt\", \"w\", encoding = \"utf-8\") as file_1:\n",
        "    file_1.write(dataset)"
      ],
      "metadata": {
        "id": "5or2cgF-2G-a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"final_dataset.txt\", \"r\", encoding = \"utf-8\") as data:\n",
        "  data = data.read()"
      ],
      "metadata": {
        "id": "_vkkbB5R2ICb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "total_characters = len(data)\n",
        "total_tokens = len(tokenizer.encode(data))\n",
        "print(\"Characters:\", total_characters)\n",
        "print(\"Tokens:\", total_tokens)"
      ],
      "metadata": {
        "id": "M89kVVTQTTE1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "221c86fa-9798-43f1-941f-14591ac4b561"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Characters: 1762018\n",
            "Tokens: 480074\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "GPT_CONFIG_124M = {\n",
        "    #the number of unique tokens that the model can recognize and generate.\n",
        "    \"vocabulary_size\": 50257,\n",
        "\n",
        "    #the maximum number of tokens the model can process in a single forward pass.\n",
        "    \"context_length\": 1024,\n",
        "\n",
        "    #the size of the vector space used to represent each token.\n",
        "    \"embd_dimension\": 768,\n",
        "\n",
        "    #the number of attention heads in each transformer layer.\n",
        "    \"n_heads\": 12,\n",
        "\n",
        "    #the number of transformer layers stacked on top of each other.\n",
        "    \"n_layers\": 12,\n",
        "\n",
        "    #the probability of randomly disabling neurons during training.\n",
        "    \"dropout_rate\": 0.1,\n",
        "\n",
        "    #indicates whether bias terms are included in the query, key, and value projections of the attention mechanism.\n",
        "    \"qkv_bias\": False\n",
        "}"
      ],
      "metadata": {
        "id": "oiuluGh-uRM7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = tiktoken.get_encoding(\"gpt2\")"
      ],
      "metadata": {
        "id": "V8qQhqoSYGCu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "EPWooqCwvImG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LayerNorm(nn.Module):\n",
        "    def __init__(self, emb_dim):\n",
        "        super().__init__()\n",
        "        self.eps = 1e-5\n",
        "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
        "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
        "\n",
        "    def forward(self, x):\n",
        "        mean = x.mean(dim=-1, keepdim=True)\n",
        "        var = x.var(dim=-1, keepdim=True, unbiased=False)\n",
        "        norm_x = (x - mean) / torch.sqrt(var + self.eps)\n",
        "        return self.scale * norm_x + self.shift"
      ],
      "metadata": {
        "id": "0JA8mWq3uzQH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#defines GELU function class\n",
        "class GELU(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return 0.5 * x * (1 + torch.tanh(\n",
        "            torch.sqrt(torch.tensor(2.0 / torch.pi)) *\n",
        "            (x + 0.044715 * torch.pow(x, 3))\n",
        "        ))"
      ],
      "metadata": {
        "id": "Ga8KR4T_vShO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#defines feedforward as class\n",
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Linear(cfg[\"embd_dimension\"], 4 * cfg[\"embd_dimension\"]),\n",
        "            GELU(),\n",
        "            nn.Linear(4 * cfg[\"embd_dimension\"], cfg[\"embd_dimension\"]),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)"
      ],
      "metadata": {
        "id": "nWyk4632vbkQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "Hvkj-4xlp_wj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n",
        "        super().__init__()\n",
        "        assert d_out % num_heads == 0, \"d_out must be divisible by num_heads\"\n",
        "\n",
        "        self.d_out = d_out\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = d_out // num_heads  # Reduce the projection dim to match desired output dim\n",
        "\n",
        "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.out_proj = nn.Linear(d_out, d_out)  # Linear layer to combine head outputs\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.register_buffer('mask', torch.triu(torch.ones(context_length, context_length), diagonal=1))\n",
        "    def forward(self, x):\n",
        "        b, num_tokens, d_in = x.shape\n",
        "\n",
        "        keys = self.W_key(x)  # Shape: (b, num_tokens, d_out)\n",
        "        queries = self.W_query(x)\n",
        "        values = self.W_value(x)\n",
        "\n",
        "        # We implicitly split the matrix by adding a `num_heads` dimension\n",
        "        # Unroll last dim: (b, num_tokens, d_out) -> (b, num_tokens, num_heads, head_dim)\n",
        "        keys = keys.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "        values = values.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "        queries = queries.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "        keys = keys.transpose(1, 2)\n",
        "        queries = queries.transpose(1, 2)\n",
        "        values = values.transpose(1, 2)\n",
        "        attn_scores = queries @ keys.transpose(2, 3)  # Dot product for each head\n",
        "\n",
        "        # Original mask truncated to the number of tokens and converted to boolean\n",
        "        mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n",
        "\n",
        "        # Use the mask to fill attention scores\n",
        "        attn_scores.masked_fill_(mask_bool, -torch.inf)\n",
        "\n",
        "        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
        "        attn_weights = self.dropout(attn_weights)\n",
        "\n",
        "        # Shape: (b, num_tokens, num_heads, head_dim)\n",
        "        context_vec = (attn_weights @ values).transpose(1, 2)\n",
        "\n",
        "        # Combine heads, where self.d_out = self.num_heads * self.head_dim\n",
        "        context_vec = context_vec.contiguous().view(b, num_tokens, self.d_out)\n",
        "        context_vec = self.out_proj(context_vec)  # optional projection\n",
        "\n",
        "        return context_vec"
      ],
      "metadata": {
        "id": "RBlJFawIoq-V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.att = MultiHeadAttention(\n",
        "            d_in=cfg[\"embd_dimension\"],\n",
        "            d_out=cfg[\"embd_dimension\"],\n",
        "            context_length=cfg[\"context_length\"],\n",
        "            num_heads=cfg[\"n_heads\"],\n",
        "            dropout=cfg[\"dropout_rate\"],\n",
        "            qkv_bias=cfg[\"qkv_bias\"])\n",
        "        self.ff = FeedForward(cfg)\n",
        "        self.norm1 = LayerNorm(cfg[\"embd_dimension\"])\n",
        "        self.norm2 = LayerNorm(cfg[\"embd_dimension\"])\n",
        "        self.drop_shortcut = nn.Dropout(cfg[\"dropout_rate\"])\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Shortcut connection for attention block\n",
        "        shortcut = x\n",
        "        x = self.norm1(x)\n",
        "        x = self.att(x)  # Shape [batch_size, num_tokens, emb_size]\n",
        "        x = self.drop_shortcut(x)\n",
        "        x = x + shortcut  # Add the original input back\n",
        "\n",
        "        # Shortcut connection for feed forward block\n",
        "        shortcut = x\n",
        "        x = self.norm2(x)\n",
        "        x = self.ff(x)\n",
        "        x = self.drop_shortcut(x)\n",
        "        x = x + shortcut  # Add the original input back\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "2U-xdcEpvxDQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GPTModel(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.tok_emb = nn.Embedding(cfg[\"vocabulary_size\"], cfg[\"embd_dimension\"])\n",
        "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"embd_dimension\"])\n",
        "        self.drop_emb = nn.Dropout(cfg[\"dropout_rate\"])\n",
        "\n",
        "        self.trf_blocks = nn.Sequential(\n",
        "            *[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])])\n",
        "\n",
        "        self.final_norm = LayerNorm(cfg[\"embd_dimension\"])\n",
        "        self.out_head = nn.Linear(\n",
        "            cfg[\"embd_dimension\"], cfg[\"vocabulary_size\"], bias=False\n",
        "        )\n",
        "\n",
        "    def forward(self, in_idx):\n",
        "        batch_size, seq_len = in_idx.shape\n",
        "        tok_embeds = self.tok_emb(in_idx)\n",
        "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
        "        x = tok_embeds + pos_embeds  # Shape [batch_size, num_tokens, emb_size]\n",
        "        x = self.drop_emb(x)\n",
        "        x = self.trf_blocks(x)\n",
        "        x = self.final_norm(x)\n",
        "        logits = self.out_head(x)\n",
        "        return logits"
      ],
      "metadata": {
        "id": "H9U3oZJRwEGW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text(model, idx, max_new_tokens, context_size):\n",
        "    for _ in range(max_new_tokens):\n",
        "        idx_cond = idx[:, -context_size:]\n",
        "        with torch.no_grad():\n",
        "            logits = model(idx_cond)\n",
        "\n",
        "        logits = logits[:, -1, :]\n",
        "        probas = torch.softmax(logits, dim=-1)\n",
        "        idx_next = torch.argmax(probas, dim=-1, keepdim=True)\n",
        "        idx = torch.cat((idx, idx_next), dim=1)\n",
        "\n",
        "    return idx"
      ],
      "metadata": {
        "id": "5nlkIqnqwZKS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch\n",
        "start_context = \"Hello, I am\"\n",
        "encoded = tokenizer.encode(start_context)\n",
        "print(\"encoded:\", encoded)\n",
        "encoded_tensor = torch.tensor(encoded).unsqueeze(0)\n",
        "print(\"encoded_tensor.shape:\", encoded_tensor.shape)"
      ],
      "metadata": {
        "id": "6J9Tltu7xk8b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "919070c8-649f-4961-d825-34f2c4caaa2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "encoded: [15496, 11, 314, 716]\n",
            "encoded_tensor.shape: torch.Size([1, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = GPTModel(GPT_CONFIG_124M)\n",
        "model.eval()\n",
        "out = generate_text(\n",
        "     model=model,\n",
        "     idx=encoded_tensor,\n",
        "     max_new_tokens=6,\n",
        "     context_size=GPT_CONFIG_124M[\"context_length\"]\n",
        ")\n",
        "print(\"Output:\", out)\n",
        "print(\"Output length:\", len(out[0]))"
      ],
      "metadata": {
        "id": "ERBHtrTgwh2Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb5532b9-02ad-4a4c-811e-aa877cf66af1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output: tensor([[15496,    11,   314,   716, 36411, 15645, 33738, 44060, 21533, 15265]])\n",
            "Output length: 10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken\n",
        "def text_to_token_ids(text, tokenizer):\n",
        "    encoded = tokenizer.encode(text, allowed_special = {'<|endoftext|>'})\n",
        "    encoded_tensor = torch.tensor(encoded).unsqueeze(0)\n",
        "    return encoded_tensor\n",
        "\n",
        "def token_ids_to_text(token_ids, tokenizer):\n",
        "    flat = token_ids.squeeze(0)\n",
        "    return tokenizer.decode(flat.tolist())\n",
        "\n",
        "start_context = \"Every effort moves you\"\n",
        "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "\n",
        "token_ids = generate_text(\n",
        "    model = model,\n",
        "    idx = text_to_token_ids(start_context, tokenizer),\n",
        "    max_new_tokens = 10,\n",
        "    context_size = GPT_CONFIG_124M[\"context_length\"]\n",
        ")\n",
        "\n",
        "print(\"Output text: \\n\", token_ids_to_text(token_ids, tokenizer))"
      ],
      "metadata": {
        "id": "XHfdPxM30QQo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b932dd83-7bd6-4f81-d420-49274aab25a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output text: \n",
            " Every effort moves you vote spew phosph 37xi meth GravesRussell pumpedGrey\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "raw_text = data\n",
        "total_characters = len(raw_text)\n",
        "total_tokens = len(tokenizer.encode(raw_text))\n",
        "print(\"Characters:\", total_characters)\n",
        "print(\"Tokens:\", total_tokens)"
      ],
      "metadata": {
        "id": "cFbx8n-X0XEb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "359c23d7-3aea-4af0-a9bf-7979d407b10a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Characters: 1762018\n",
            "Tokens: 480074\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#using 90% data as training set and 10% as testing set\n",
        "train_ratio = 0.90\n",
        "#calculate the index where you will be splitting your data\n",
        "split_idx = int(train_ratio * len(data))\n",
        "train_data = data[:split_idx]\n",
        "val_data = data[split_idx:]"
      ],
      "metadata": {
        "id": "eZSks5_V0mLs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "class GPTDatasetV1(Dataset):\n",
        "     def __init__(self, txt, tokenizer, max_length, stride):\n",
        "         self.input_ids = []\n",
        "         self.target_ids = []\n",
        "\n",
        "         token_ids = tokenizer.encode(txt)\n",
        "\n",
        "         for i in range(0, len(token_ids) - max_length, stride):\n",
        "             input_chunk = token_ids[i:i + max_length]\n",
        "             target_chunk = token_ids[i + 1: i + max_length + 1]\n",
        "             self.input_ids.append(torch.tensor(input_chunk))\n",
        "             self.target_ids.append(torch.tensor(target_chunk))\n",
        "\n",
        "     def __len__(self):\n",
        "        return len(self.input_ids)\n",
        "\n",
        "     def __getitem__(self, idx):\n",
        "        return self.input_ids[idx], self.target_ids[idx]"
      ],
      "metadata": {
        "id": "73u7glRU0sp1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dataloader_v1(txt, batch_size=4, max_length=256,\n",
        "                         stride=128, shuffle=True, drop_last=True,\n",
        "                         num_workers=0):\n",
        "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "    dataset = GPTDatasetV1(txt, tokenizer, max_length, stride)\n",
        "    dataloader = DataLoader(\n",
        "        dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=shuffle,\n",
        "        drop_last=drop_last,\n",
        "        num_workers=num_workers\n",
        " )\n",
        "\n",
        "    return dataloader"
      ],
      "metadata": {
        "id": "T29HS8SD0uMg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = create_dataloader_v1(\n",
        "     train_data,\n",
        "     batch_size=4,\n",
        "     max_length=GPT_CONFIG_124M[\"context_length\"],\n",
        "     stride=GPT_CONFIG_124M[\"context_length\"],\n",
        "     drop_last=True,\n",
        "     shuffle=True,\n",
        "     num_workers=0\n",
        ")\n",
        "\n",
        "\n",
        "val_loader = create_dataloader_v1(\n",
        "     val_data,\n",
        "     batch_size=4,\n",
        "     max_length=GPT_CONFIG_124M[\"context_length\"],\n",
        "     stride=GPT_CONFIG_124M[\"context_length\"],\n",
        "     drop_last=False,\n",
        "     shuffle=False,\n",
        "     num_workers=0\n",
        ")"
      ],
      "metadata": {
        "id": "4I9Pqydn1C6v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_loss_batch(input_batch, target_batch, model, device):\n",
        "     input_batch = input_batch.to(device)\n",
        "     target_batch = target_batch.to(device)\n",
        "     logits = model(input_batch)\n",
        "     loss = torch.nn.functional.cross_entropy(\n",
        "         logits.flatten(0, 1), target_batch.flatten()\n",
        "     )\n",
        "     return loss"
      ],
      "metadata": {
        "id": "e6yfsI3ECux8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
        "     total_loss = 0.\n",
        "     if len(data_loader) == 0:\n",
        "         return float(\"nan\")\n",
        "     elif num_batches is None:\n",
        "         num_batches = len(data_loader)\n",
        "     else:\n",
        "         num_batches = min(num_batches, len(data_loader))\n",
        "     for i, (input_batch, target_batch) in enumerate(data_loader):\n",
        "         if i < num_batches:\n",
        "             loss = calc_loss_batch(\n",
        "                 input_batch, target_batch, model, device\n",
        "             )\n",
        "             total_loss += loss.item()\n",
        "         else:\n",
        "             break\n",
        "     return total_loss / num_batches"
      ],
      "metadata": {
        "id": "-zIMujslIBJ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "with torch.no_grad():\n",
        "    train_loss = calc_loss_loader(train_loader, model, device)\n",
        "    val_loss = calc_loss_loader(val_loader, model, device)\n",
        "print(\"Training loss:\", train_loss)\n",
        "print(\"Validation loss:\", val_loss)"
      ],
      "metadata": {
        "id": "3qdbpTtRIV1d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41f97924-30c4-4a1d-cd3f-819a81547b9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss: 11.01148034050351\n",
            "Validation loss: 11.00675638516744\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "EuBDYZ2zW80t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model_simple(model, train_loader, val_loader,\n",
        "                       optimizer, device, num_epochs,\n",
        "                       eval_freq, eval_iter, start_context, tokenizer):\n",
        "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
        "    tokens_seen, global_step = 0, -1\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        for input_batch, target_batch in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            loss = calc_loss_batch(\n",
        "                input_batch, target_batch, model, device\n",
        "            )\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            tokens_seen += input_batch.numel()\n",
        "            global_step += 1\n",
        "\n",
        "            if global_step % eval_freq == 0:\n",
        "                train_loss, val_loss = evaluate_model(\n",
        "                    model, train_loader, val_loader, device, eval_iter)\n",
        "\n",
        "                train_losses.append(train_loss)\n",
        "                val_losses.append(val_loss)\n",
        "                track_tokens_seen.append(tokens_seen)\n",
        "\n",
        "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
        "                      f\"Train loss {train_loss:.3f}, \"\n",
        "                      f\"Val loss {val_loss:.3f}\"\n",
        "                )\n",
        "\n",
        "        generate_and_print_sample(\n",
        "            model, tokenizer, device, start_context\n",
        "        )\n",
        "    return train_losses, val_losses, track_tokens_seen"
      ],
      "metadata": {
        "id": "dWC0N_OWI4A_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
        "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
        "    model.train()\n",
        "    return train_loss, val_loss\n",
        "\n"
      ],
      "metadata": {
        "id": "U13cibgqI_Ce"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
        "    model.eval()\n",
        "    context_size = model.pos_emb.weight.shape[0]\n",
        "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
        "    with torch.no_grad():\n",
        "        token_ids = generate_text(\n",
        "            model=model, idx=encoded,\n",
        "            max_new_tokens=50, context_size=context_size\n",
        "        )\n",
        "    decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
        "    print(decoded_text.replace(\"\\n\", \" \"))  # Compact print format\n",
        "    model.train()"
      ],
      "metadata": {
        "id": "obz0m2i_JERZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "model = GPTModel(GPT_CONFIG_124M)\n",
        "model.to(device)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=0.00001, weight_decay=0.1)\n",
        "\n",
        "num_epochs = 5\n",
        "train_losses, val_losses, tokens_seen = train_model_simple(\n",
        "    model, train_loader, val_loader, optimizer, device,\n",
        "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
        "    start_context=\"The work is mysterious and important\", tokenizer=tokenizer\n",
        ")\n"
      ],
      "metadata": {
        "id": "5ZMuVRTwJycZ",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0eee9584-6c25-4f1f-dea6-2b946745defb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 1 (Step 000000): Train loss 10.838, Val loss 10.854\n",
            "Ep 1 (Step 000005): Train loss 10.119, Val loss 10.154\n",
            "Ep 1 (Step 000010): Train loss 9.610, Val loss 9.598\n",
            "Ep 1 (Step 000015): Train loss 9.258, Val loss 9.278\n",
            "Ep 1 (Step 000020): Train loss 9.087, Val loss 9.070\n",
            "Ep 1 (Step 000025): Train loss 8.922, Val loss 8.911\n",
            "Ep 1 (Step 000030): Train loss 8.740, Val loss 8.786\n",
            "Ep 1 (Step 000035): Train loss 8.652, Val loss 8.665\n",
            "Ep 1 (Step 000040): Train loss 8.500, Val loss 8.547\n",
            "Ep 1 (Step 000045): Train loss 8.448, Val loss 8.437\n",
            "Ep 1 (Step 000050): Train loss 8.203, Val loss 8.328\n",
            "Ep 1 (Step 000055): Train loss 8.201, Val loss 8.219\n",
            "Ep 1 (Step 000060): Train loss 7.985, Val loss 8.113\n",
            "Ep 1 (Step 000065): Train loss 7.964, Val loss 8.019\n",
            "Ep 1 (Step 000070): Train loss 7.886, Val loss 7.944\n",
            "Ep 1 (Step 000075): Train loss 7.823, Val loss 7.880\n",
            "Ep 1 (Step 000080): Train loss 7.702, Val loss 7.763\n",
            "Ep 1 (Step 000085): Train loss 7.408, Val loss 7.648\n",
            "Ep 1 (Step 000090): Train loss 7.555, Val loss 7.560\n",
            "Ep 1 (Step 000095): Train loss 7.469, Val loss 7.476\n",
            "Ep 1 (Step 000100): Train loss 7.385, Val loss 7.392\n",
            "The work is mysterious and important                                                  \n",
            "Ep 2 (Step 000105): Train loss 7.292, Val loss 7.317\n",
            "Ep 2 (Step 000110): Train loss 6.987, Val loss 7.250\n",
            "Ep 2 (Step 000115): Train loss 7.006, Val loss 7.179\n",
            "Ep 2 (Step 000120): Train loss 7.072, Val loss 7.113\n",
            "Ep 2 (Step 000125): Train loss 6.703, Val loss 7.049\n",
            "Ep 2 (Step 000130): Train loss 6.644, Val loss 6.989\n",
            "Ep 2 (Step 000135): Train loss 6.913, Val loss 6.933\n",
            "Ep 2 (Step 000140): Train loss 6.762, Val loss 6.879\n",
            "Ep 2 (Step 000145): Train loss 6.708, Val loss 6.830\n",
            "Ep 2 (Step 000150): Train loss 6.668, Val loss 6.781\n",
            "Ep 2 (Step 000155): Train loss 6.186, Val loss 6.735\n",
            "Ep 2 (Step 000160): Train loss 6.589, Val loss 6.695\n",
            "Ep 2 (Step 000165): Train loss 6.549, Val loss 6.658\n",
            "Ep 2 (Step 000170): Train loss 6.578, Val loss 6.619\n",
            "Ep 2 (Step 000175): Train loss 6.392, Val loss 6.582\n",
            "Ep 2 (Step 000180): Train loss 6.449, Val loss 6.544\n",
            "Ep 2 (Step 000185): Train loss 6.339, Val loss 6.509\n",
            "Ep 2 (Step 000190): Train loss 6.381, Val loss 6.478\n",
            "Ep 2 (Step 000195): Train loss 6.330, Val loss 6.449\n",
            "Ep 2 (Step 000200): Train loss 6.326, Val loss 6.420\n",
            "Ep 2 (Step 000205): Train loss 6.307, Val loss 6.390\n",
            "The work is mysterious and important                                                  \n",
            "Ep 3 (Step 000210): Train loss 6.287, Val loss 6.361\n",
            "Ep 3 (Step 000215): Train loss 6.196, Val loss 6.337\n",
            "Ep 3 (Step 000220): Train loss 6.218, Val loss 6.319\n",
            "Ep 3 (Step 000225): Train loss 6.066, Val loss 6.302\n",
            "Ep 3 (Step 000230): Train loss 6.147, Val loss 6.284\n",
            "Ep 3 (Step 000235): Train loss 6.175, Val loss 6.265\n",
            "Ep 3 (Step 000240): Train loss 6.044, Val loss 6.243\n",
            "Ep 3 (Step 000245): Train loss 6.101, Val loss 6.222\n",
            "Ep 3 (Step 000250): Train loss 6.069, Val loss 6.204\n",
            "Ep 3 (Step 000255): Train loss 6.101, Val loss 6.190\n",
            "Ep 3 (Step 000260): Train loss 5.994, Val loss 6.179\n",
            "Ep 3 (Step 000265): Train loss 6.088, Val loss 6.161\n",
            "Ep 3 (Step 000270): Train loss 5.772, Val loss 6.146\n",
            "Ep 3 (Step 000275): Train loss 5.951, Val loss 6.131\n",
            "Ep 3 (Step 000280): Train loss 5.944, Val loss 6.116\n",
            "Ep 3 (Step 000285): Train loss 6.114, Val loss 6.104\n",
            "Ep 3 (Step 000290): Train loss 5.814, Val loss 6.092\n",
            "Ep 3 (Step 000295): Train loss 5.807, Val loss 6.079\n",
            "Ep 3 (Step 000300): Train loss 5.924, Val loss 6.067\n",
            "Ep 3 (Step 000305): Train loss 5.936, Val loss 6.059\n",
            "Ep 3 (Step 000310): Train loss 5.948, Val loss 6.050\n",
            "The work is mysterious and important          ” ” ” ” ” ” ” ” ” ” ” ” ” �\n",
            "Ep 4 (Step 000315): Train loss 5.806, Val loss 6.039\n",
            "Ep 4 (Step 000320): Train loss 5.806, Val loss 6.032\n",
            "Ep 4 (Step 000325): Train loss 5.940, Val loss 6.020\n",
            "Ep 4 (Step 000330): Train loss 5.862, Val loss 6.010\n",
            "Ep 4 (Step 000335): Train loss 5.900, Val loss 5.999\n",
            "Ep 4 (Step 000340): Train loss 5.723, Val loss 5.990\n",
            "Ep 4 (Step 000345): Train loss 5.731, Val loss 5.982\n",
            "Ep 4 (Step 000350): Train loss 5.809, Val loss 5.973\n",
            "Ep 4 (Step 000355): Train loss 5.768, Val loss 5.964\n",
            "Ep 4 (Step 000360): Train loss 5.835, Val loss 5.957\n",
            "Ep 4 (Step 000365): Train loss 5.551, Val loss 5.950\n",
            "Ep 4 (Step 000370): Train loss 5.790, Val loss 5.942\n",
            "Ep 4 (Step 000375): Train loss 5.733, Val loss 5.932\n",
            "Ep 4 (Step 000380): Train loss 5.371, Val loss 5.924\n",
            "Ep 4 (Step 000385): Train loss 5.888, Val loss 5.914\n",
            "Ep 4 (Step 000390): Train loss 5.722, Val loss 5.907\n",
            "Ep 4 (Step 000395): Train loss 5.766, Val loss 5.908\n",
            "Ep 4 (Step 000400): Train loss 5.742, Val loss 5.904\n",
            "Ep 4 (Step 000405): Train loss 5.583, Val loss 5.893\n",
            "Ep 4 (Step 000410): Train loss 5.659, Val loss 5.879\n",
            "Ep 4 (Step 000415): Train loss 5.739, Val loss 5.870\n",
            "The work is mysterious and important, and     ” ” ” ” ” ” ” ” ” ” ” ” ” ” �\n",
            "Ep 5 (Step 000420): Train loss 5.401, Val loss 5.860\n",
            "Ep 5 (Step 000425): Train loss 5.782, Val loss 5.852\n",
            "Ep 5 (Step 000430): Train loss 5.703, Val loss 5.847\n",
            "Ep 5 (Step 000435): Train loss 5.626, Val loss 5.843\n",
            "Ep 5 (Step 000440): Train loss 5.661, Val loss 5.835\n",
            "Ep 5 (Step 000445): Train loss 5.640, Val loss 5.829\n",
            "Ep 5 (Step 000450): Train loss 5.583, Val loss 5.823\n",
            "Ep 5 (Step 000455): Train loss 5.700, Val loss 5.813\n",
            "Ep 5 (Step 000460): Train loss 5.680, Val loss 5.808\n",
            "Ep 5 (Step 000465): Train loss 5.677, Val loss 5.808\n",
            "Ep 5 (Step 000470): Train loss 5.620, Val loss 5.800\n",
            "Ep 5 (Step 000475): Train loss 5.407, Val loss 5.789\n",
            "Ep 5 (Step 000480): Train loss 5.625, Val loss 5.779\n",
            "Ep 5 (Step 000485): Train loss 5.619, Val loss 5.768\n",
            "Ep 5 (Step 000490): Train loss 5.478, Val loss 5.761\n",
            "Ep 5 (Step 000495): Train loss 5.416, Val loss 5.753\n",
            "Ep 5 (Step 000500): Train loss 5.533, Val loss 5.751\n",
            "Ep 5 (Step 000505): Train loss 5.331, Val loss 5.747\n",
            "Ep 5 (Step 000510): Train loss 5.373, Val loss 5.745\n",
            "Ep 5 (Step 000515): Train loss 5.496, Val loss 5.739\n",
            "Ep 5 (Step 000520): Train loss 5.458, Val loss 5.729\n",
            "The work is mysterious and important   ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ”\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.ticker import MaxNLocator\n",
        "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
        "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
        "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
        "    ax1.plot(\n",
        "        epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\"\n",
        "    )\n",
        "    ax1.set_xlabel(\"Epochs\")\n",
        "    ax1.set_ylabel(\"Loss\")\n",
        "    ax1.legend(loc=\"upper right\")\n",
        "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
        "    ax2 = ax1.twiny()\n",
        "    ax2.plot(tokens_seen, train_losses, alpha=0)\n",
        "    ax2.set_xlabel(\"Tokens seen\")\n",
        "    fig.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "WQ8mDEykXpWI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
        "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
      ],
      "metadata": {
        "id": "NbERYpPaiCVg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "outputId": "e6431dd2-8b7f-419e-d71d-9e444ff9ca90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x300 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_fun(context):\n",
        "  generate_and_print_sample(model, tokenizer, device, context)\n"
      ],
      "metadata": {
        "id": "611GWIk2in0B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "context = input(\"Enter first context:\")\n",
        "generate_fun(context)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WQcdheG3cyWw",
        "outputId": "7b677482-224e-4611-f1b1-bfc2aa989a13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter first context:pride and prejudice is wonderful movie\n",
            "pride and prejudice is wonderful movie, and    ” ” ” ” ” ” ” ” ” ” ” ” ” ” ”\n"
          ]
        }
      ]
    }
  ]
}